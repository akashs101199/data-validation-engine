# ğŸ§ª Data Validation Engine for Machine Learning Pipelines

A modular and scalable system for validating datasets in machine learning workflows. It supports schema validation, business rule enforcement, data drift detection, and generates detailed interactive dashboards using **Streamlit**.

---

## ğŸš€ Features

- âœ… Schema validation using column data types and structure  
- ğŸ“‹ Custom business rules for domain-specific logic  
- ğŸ” Data drift detection (between reference and production data)  
- ğŸ“Š Streamlit dashboard for summary and visualizations  
- ğŸ“‚ Modular codebase (easy to extend and customize)  
- ğŸ“ Detailed failure reports (rows, rules, charts)

---

## ğŸ“ Project Structure

```

data-validation-engine/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ digital\_wallet\_ltv\_dataset.csv
â”‚   â””â”€â”€ validated\_output.csv
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ streamlit\_app.py
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ loader.py
â”œâ”€â”€ validation/
â”‚   â”œâ”€â”€ schema\_validation.py
â”‚   â”œâ”€â”€ business\_rules.py
â”‚   â”œâ”€â”€ drift\_detector.py
â”‚   â””â”€â”€ dashboard\_streamlit\_data.py
â”œâ”€â”€ export/
â”‚   â””â”€â”€ writer.py
â”œâ”€â”€ reports/
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Installation

### 1. Clone the repository

```bash
git clone https://github.com/akashs101199/data-validation-engine.git
cd data-validation-engine
````

### 2. Set up virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ“¦ Usage Guide

### â–¶ï¸ Run the Data Validation Pipeline

```bash
python main.py
```

This will:

1. Load the raw dataset
2. Validate schema
3. Apply business rules
4. Export clean data
5. Generate reports
6. Prepare dashboard data

### ğŸ“Š Launch the Dashboard

```bash
streamlit run dashboards/streamlit_app.py
```

---

## ğŸ§ª Example Business Rules

Defined in `business_rules.py`:

* `customer_id` must not be null
* `ltv` must be greater than 0
* `score` should be between 0 and 1
* `ltv` positive if churned
* `signup_date` must not be null or in the future

---

## ğŸ“Š Output Artifacts

After running the pipeline, the following are generated:

* `reports/validation_summary.csv`
* `reports/failed_rules.csv`
* `reports/failed_rows.csv`
* `reports/failure_chart.png`
* `data/validated_output.csv`

---

## ğŸ“‰ Drift Detection

Use:

```python
detect_drift(reference_df, new_df)
```

Generates:

* `dashboards/drift_report.html`

---

## ğŸ“· Dashboard Preview

| Validation Summary           | Failed Rules               | Drift Report               |
| ---------------------------- | -------------------------- | -------------------------- |
| ![](screenshots/summary.png) | ![](screenshots/rules.png) | ![](screenshots/drift.png) |

---

## ğŸ¤– Use Cases

* Data intake for ML pipelines
* Feature validation
* QA for incoming datasets
* Continuous monitoring

---

## ğŸ§© Future Improvements

* YAML-configured rule sets
* Slack/email alerting
* Airflow integration
* Cloud-based validation support

---

## ğŸ§‘â€ğŸ’» Contributing

Pull requests welcome! Let's build better data pipelines together.

````

---

You can save this as `README.md` and push it:

```bash
git add README.md
git commit -m "ğŸ“ Updated README: removed license section"
git push origin main
````
# data-validation-enginer
